{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Week 7\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "- [Capstone Objectives](#Capstone-Objectives)\n",
    "- [Read in Data](#Read-in-Data)\n",
    "    - [Merge 2018 and 2019](#Merge-2018-and-2019)\n",
    "    - [Make advisor and firm dictionary mapper](#Make-advisor-and-firm-dictionary-mapper)\n",
    "- [EDA](#EDA)\n",
    "- [Data Cleaning](#Data-Cleaning)\n",
    "    - [Train-Test-Split](#Train-Test-Split)\n",
    "    - [Custom Cleaning Functions](#Custom-Cleaning-Functions)\n",
    "    - [Create Cleaning Pipeline](#Create-Cleaning-Pipeline)\n",
    "- [Model building](#Model-building)\n",
    "    - [Regression](#Regression)\n",
    "        - [Calculate Baseline](#Calculate-Baseline)\n",
    "        - [`sklearn` Feature Selection](#sklearn-Feature-Selection)\n",
    "        - [Make function to output deciles](#Make-function-to-output-deciles)\n",
    "    - [Classification](#Classification)\n",
    "        - [Calculate Baseline-Classification](#Calculate-Baseline-Classification)\n",
    "        - [Classification Feature Selection](#Classification-Feature-Selection)\n",
    "- [Fairness and Bias](#Fairness-and-Bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Objectives\n",
    "- Assist sales and marketing by improving their targeting\n",
    "- Predict sales for 2019 using the data for 2018\n",
    "- Estimate the probability of adding a new fund in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Transactions.csv\", parse_dates=['refresh_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTACT_ID</th>\n",
       "      <th>no_of_sales_12M_1</th>\n",
       "      <th>no_of_Redemption_12M_1</th>\n",
       "      <th>no_of_sales_12M_10K</th>\n",
       "      <th>no_of_Redemption_12M_10K</th>\n",
       "      <th>no_of_funds_sold_12M_1</th>\n",
       "      <th>no_of_funds_redeemed_12M_1</th>\n",
       "      <th>no_of_fund_sales_12M_10K</th>\n",
       "      <th>no_of_funds_Redemption_12M_10K</th>\n",
       "      <th>no_of_assetclass_sold_12M_1</th>\n",
       "      <th>no_of_assetclass_redeemed_12M_1</th>\n",
       "      <th>no_of_assetclass_sales_12M_10K</th>\n",
       "      <th>no_of_assetclass_Redemption_12M_10K</th>\n",
       "      <th>No_of_fund_curr</th>\n",
       "      <th>No_of_asset_curr</th>\n",
       "      <th>AUM</th>\n",
       "      <th>sales_curr</th>\n",
       "      <th>sales_12M</th>\n",
       "      <th>redemption_curr</th>\n",
       "      <th>redemption_12M</th>\n",
       "      <th>new_Fund_added_12M</th>\n",
       "      <th>redemption_rate</th>\n",
       "      <th>aum_AC_EQUITY</th>\n",
       "      <th>aum_AC_FIXED_INCOME_MUNI</th>\n",
       "      <th>aum_AC_FIXED_INCOME_TAXABLE</th>\n",
       "      <th>aum_AC_MONEY</th>\n",
       "      <th>aum_AC_MULTIPLE</th>\n",
       "      <th>aum_AC_PHYSICAL_COMMODITY</th>\n",
       "      <th>aum_AC_REAL_ESTATE</th>\n",
       "      <th>aum_AC_TARGET</th>\n",
       "      <th>aum_P_529</th>\n",
       "      <th>aum_P_ALT</th>\n",
       "      <th>aum_P_CEF</th>\n",
       "      <th>aum_P_ETF</th>\n",
       "      <th>aum_P_MF</th>\n",
       "      <th>aum_P_SMA</th>\n",
       "      <th>aum_P_UCITS</th>\n",
       "      <th>aum_P_UIT</th>\n",
       "      <th>refresh_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85102111664960504040</td>\n",
       "      <td>3096</td>\n",
       "      <td>6592</td>\n",
       "      <td>302</td>\n",
       "      <td>157</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1.909702e+07</td>\n",
       "      <td>399995.834888</td>\n",
       "      <td>1.259993e+07</td>\n",
       "      <td>-231714.43334</td>\n",
       "      <td>-6.557185e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012133</td>\n",
       "      <td>9.386941e+06</td>\n",
       "      <td>9.743856e+06</td>\n",
       "      <td>-9655.913728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24116.993988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.431248e+06</td>\n",
       "      <td>1.066578e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4492101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.468574e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.102100e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7583.640000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.468574e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85102140943881291064</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.164047e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.950000e+02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.164047e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.164047e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85202121774856516280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.425462e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.164760e+03</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.030151e+04</td>\n",
       "      <td>272244.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.425462e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0360380</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.262721e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.278145e+03</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.113566e+05</td>\n",
       "      <td>-2.018566e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-94729.890000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.315423e+05</td>\n",
       "      <td>-9.472989e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CONTACT_ID  no_of_sales_12M_1  no_of_Redemption_12M_1  \\\n",
       "0  85102111664960504040               3096                    6592   \n",
       "1               4492101                  0                       0   \n",
       "2  85102140943881291064                  0                       1   \n",
       "3  85202121774856516280                  1                       0   \n",
       "4               0360380                  7                       0   \n",
       "\n",
       "   no_of_sales_12M_10K  no_of_Redemption_12M_10K  no_of_funds_sold_12M_1  \\\n",
       "0                  302                       157                       8   \n",
       "1                    0                         0                       0   \n",
       "2                    0                         0                       0   \n",
       "3                    0                         0                       1   \n",
       "4                    0                         0                       1   \n",
       "\n",
       "   no_of_funds_redeemed_12M_1  no_of_fund_sales_12M_10K  \\\n",
       "0                          13                         7   \n",
       "1                           0                         0   \n",
       "2                           1                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "\n",
       "   no_of_funds_Redemption_12M_10K  no_of_assetclass_sold_12M_1  \\\n",
       "0                               7                            2   \n",
       "1                               0                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            1   \n",
       "4                               0                            1   \n",
       "\n",
       "   no_of_assetclass_redeemed_12M_1  no_of_assetclass_sales_12M_10K  \\\n",
       "0                                3                               2   \n",
       "1                                0                               0   \n",
       "2                                1                               0   \n",
       "3                                0                               0   \n",
       "4                                0                               0   \n",
       "\n",
       "   no_of_assetclass_Redemption_12M_10K  No_of_fund_curr  No_of_asset_curr  \\\n",
       "0                                    2                9                 2   \n",
       "1                                    0                0                 0   \n",
       "2                                    0                0                 0   \n",
       "3                                    0                2                 2   \n",
       "4                                    0                2                 0   \n",
       "\n",
       "            AUM     sales_curr     sales_12M  redemption_curr  redemption_12M  \\\n",
       "0  1.909702e+07  399995.834888  1.259993e+07    -231714.43334   -6.557185e+06   \n",
       "1 -1.468574e+04       0.000000  0.000000e+00          0.00000    0.000000e+00   \n",
       "2 -7.164047e+04       0.000000  0.000000e+00          0.00000   -1.950000e+02   \n",
       "3  3.425462e+05       0.000000  1.164760e+03          0.00000    0.000000e+00   \n",
       "4 -2.262721e+05       0.000000  3.278145e+03          0.00000    0.000000e+00   \n",
       "\n",
       "   new_Fund_added_12M  redemption_rate  aum_AC_EQUITY  \\\n",
       "0                   0        -0.012133   9.386941e+06   \n",
       "1                   0         0.000000  -7.102100e+03   \n",
       "2                   0         0.000000  -7.164047e+04   \n",
       "3                   1         0.000000   0.000000e+00   \n",
       "4                   0         0.000000  -1.113566e+05   \n",
       "\n",
       "   aum_AC_FIXED_INCOME_MUNI  aum_AC_FIXED_INCOME_TAXABLE  aum_AC_MONEY  \\\n",
       "0              9.743856e+06                 -9655.913728           0.0   \n",
       "1              0.000000e+00                 -7583.640000           0.0   \n",
       "2              0.000000e+00                     0.000000           0.0   \n",
       "3              7.030151e+04                272244.700000           0.0   \n",
       "4             -2.018566e+04                     0.000000           0.0   \n",
       "\n",
       "   aum_AC_MULTIPLE  aum_AC_PHYSICAL_COMMODITY  aum_AC_REAL_ESTATE  \\\n",
       "0    -24116.993988                        0.0                 0.0   \n",
       "1         0.000000                        0.0                 0.0   \n",
       "2         0.000000                        0.0                 0.0   \n",
       "3         0.000000                        0.0                 0.0   \n",
       "4    -94729.890000                        0.0                 0.0   \n",
       "\n",
       "   aum_AC_TARGET  aum_P_529  aum_P_ALT  aum_P_CEF  aum_P_ETF      aum_P_MF  \\\n",
       "0            0.0        0.0        0.0        0.0        0.0  8.431248e+06   \n",
       "1            0.0        0.0        0.0        0.0        0.0 -1.468574e+04   \n",
       "2            0.0        0.0        0.0        0.0        0.0 -7.164047e+04   \n",
       "3            0.0        0.0        0.0        0.0        0.0  3.425462e+05   \n",
       "4            0.0        0.0        0.0        0.0        0.0 -1.315423e+05   \n",
       "\n",
       "      aum_P_SMA  aum_P_UCITS  aum_P_UIT refresh_date  \n",
       "0  1.066578e+07          0.0        0.0   2017-12-31  \n",
       "1  0.000000e+00          0.0        0.0   2017-12-31  \n",
       "2  0.000000e+00          0.0        0.0   2017-12-31  \n",
       "3  0.000000e+00          0.0        0.0   2017-12-31  \n",
       "4 -9.472989e+04          0.0        0.0   2017-12-31  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['refresh_date'].dt.month\n",
    "\n",
    "# df['year'] = df['refresh_date'].dt.year\n",
    "# df['month'] = df['refresh_date'].dt.month\n",
    "\n",
    "# filt = (df['year'] == 2020) & (df['month'] == 11)\n",
    "# df.loc[filt, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make advisor dictionary mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adviser_lookup = {\n",
    "    idx: contact_id \n",
    "        for idx, contact_id in enumerate(df['CONTACT_ID'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0082583'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adviser_lookup[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine `sales_curr` and `sales_12M`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_sales'] = df['sales_curr'] + df['sales_12M']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#EDA)\n",
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -yc conda-forge pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# missing_diagrams = {\n",
    "#     'heatmap': True, 'dendrogram': True, 'matrix':True, 'bar': True,\n",
    "# }\n",
    "\n",
    "# profile = ProfileReport(df, title='Nuveen Profile Report', missing_diagrams=missing_diagrams)\n",
    "\n",
    "# profile.to_file(output_file=\"nuveen_profiling.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you change ANYTHING with the data - besides the above :) - do your train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    'CONTACT_ID', 'no_of_sales_12M_1', 'no_of_Redemption_12M_1',\n",
    "    'no_of_sales_12M_10K', 'no_of_Redemption_12M_10K',\n",
    "    'no_of_funds_sold_12M_1', 'no_of_funds_redeemed_12M_1',\n",
    "    'no_of_fund_sales_12M_10K', 'no_of_funds_Redemption_12M_10K',\n",
    "    'no_of_assetclass_sold_12M_1', 'no_of_assetclass_redeemed_12M_1',\n",
    "    'no_of_assetclass_sales_12M_10K', 'no_of_assetclass_Redemption_12M_10K',\n",
    "    'No_of_fund_curr', 'No_of_asset_curr', 'AUM', 'sales_curr', 'sales_12M',\n",
    "    'redemption_curr', 'redemption_12M', 'new_Fund_added_12M',\n",
    "    'redemption_rate', 'aum_AC_EQUITY', 'aum_AC_FIXED_INCOME_MUNI',\n",
    "    'aum_AC_FIXED_INCOME_TAXABLE', 'aum_AC_MONEY', 'aum_AC_MULTIPLE',\n",
    "    'aum_AC_PHYSICAL_COMMODITY', 'aum_AC_REAL_ESTATE', 'aum_AC_TARGET',\n",
    "    'aum_P_529', 'aum_P_ALT', 'aum_P_CEF', 'aum_P_ETF', 'aum_P_MF',\n",
    "    'aum_P_SMA', 'aum_P_UCITS', 'aum_P_UIT', 'refresh_date',\n",
    "]\n",
    "TARGETS = 'total_sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a variable to keep all of the columns we want to drop\n",
    "COLS_TO_DROP = [\n",
    "    'CONTACT_ID', 'sales_curr', 'sales_12M', \n",
    "    'refresh_date', 'new_Fund_added_12M','no_of_Redemption_12M_1',\n",
    "]\n",
    "\n",
    "COLS_TO_KEEP = [\n",
    "    'no_of_sales_12M_1', \n",
    "    'no_of_sales_12M_10K', 'no_of_Redemption_12M_10K',\n",
    "    'no_of_funds_sold_12M_1', 'no_of_funds_redeemed_12M_1',\n",
    "    'no_of_fund_sales_12M_10K', 'no_of_funds_Redemption_12M_10K',\n",
    "    'no_of_assetclass_sold_12M_1', 'no_of_assetclass_redeemed_12M_1',\n",
    "    'no_of_assetclass_sales_12M_10K', 'no_of_assetclass_Redemption_12M_10K',\n",
    "    'No_of_fund_curr', 'No_of_asset_curr', 'AUM', 'redemption_curr', \n",
    "    'redemption_12M', 'redemption_rate', 'aum_AC_EQUITY', \n",
    "    'aum_AC_FIXED_INCOME_MUNI', 'aum_AC_FIXED_INCOME_TAXABLE', 'aum_AC_MONEY', \n",
    "    'aum_AC_MULTIPLE', 'aum_AC_PHYSICAL_COMMODITY', 'aum_AC_REAL_ESTATE', \n",
    "    'aum_AC_TARGET', 'aum_P_529', 'aum_P_ALT', 'aum_P_CEF', 'aum_P_ETF', \n",
    "    'aum_P_MF', 'aum_P_SMA', 'aum_P_UCITS', 'aum_P_UIT',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rows = df['refresh_date'].dt.year.isin([2017, 2018, 2019])\n",
    "testing_rows = df['refresh_date'].dt.year.isin([2020])\n",
    "\n",
    "X = df.loc[training_rows, FEATURES].copy()\n",
    "y_reg = df.loc[training_rows, TARGETS].copy()\n",
    "y_cl = df.loc[training_rows, 'new_Fund_added_12M'].copy()\n",
    "\n",
    "y_holdout_test = df.loc[testing_rows, TARGETS].copy() # forget about this for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Cleaning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create functions that do some basic housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_columns(df):\n",
    "    '''extract out columns not listed in COLS_TO_DROP variable'''\n",
    "    cols_to_keep = [col for col in df.columns if col not in COLS_TO_DROP]\n",
    "    return df.loc[:, cols_to_keep].copy()\n",
    "\n",
    "\n",
    "def fillna_values(df):\n",
    "    '''fill nan values with zero'''\n",
    "    if isinstance(df, type(pd.Series(dtype='float64'))):\n",
    "        return df.fillna(0)\n",
    "    num_df = df.select_dtypes(include=['number']).fillna(0)\n",
    "    non_num_df = df.select_dtypes(exclude=['number'])\n",
    "    return pd.concat([num_df, non_num_df], axis=1)\n",
    "\n",
    "\n",
    "def negative_to_zero(series):\n",
    "    if isinstance(series, type(pd.Series(dtype='float64'))):\n",
    "        return series.apply(lambda x: max(0, x))\n",
    "    else:\n",
    "        return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.3, random_state=24\n",
    ")\n",
    "y_train_cl, y_test_cl = y_cl[y_train_reg.index], y_cl[y_test_reg.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Create Cleaning Pipeline\n",
    "\n",
    "- Pipeline for target variable\n",
    "- Pipeline for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_columns_trans = FunctionTransformer(extract_columns)\n",
    "fillna_values_trans = FunctionTransformer(fillna_values)\n",
    "negative_to_zero_trans = FunctionTransformer(negative_to_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pipeline for regression target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_redemption(df):\n",
    "    redemp_cols = [col for col in df.columns if 'redemption' in col.lower()]\n",
    "    return df[redemp_cols].copy()\n",
    "\n",
    "def replace_with_zero(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: min(0, x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_redemption_trans = FunctionTransformer(extract_redemption)\n",
    "replace_with_zero_trans = FunctionTransformer(replace_with_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "redemption_pipe = Pipeline([\n",
    "    ('extract_redemption_trans', extract_redemption_trans),\n",
    "    ('replace_with_zero_trans', replace_with_zero_trans),\n",
    "    ('StandardScaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_Redemption_12M_1</th>\n",
       "      <th>no_of_Redemption_12M_10K</th>\n",
       "      <th>no_of_funds_Redemption_12M_10K</th>\n",
       "      <th>no_of_assetclass_Redemption_12M_10K</th>\n",
       "      <th>redemption_curr</th>\n",
       "      <th>redemption_12M</th>\n",
       "      <th>redemption_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068414</td>\n",
       "      <td>0.116706</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068414</td>\n",
       "      <td>0.116706</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045743</td>\n",
       "      <td>-0.994636</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30070</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067219</td>\n",
       "      <td>0.091516</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232410</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068414</td>\n",
       "      <td>0.116706</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190609</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068414</td>\n",
       "      <td>0.116706</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068414</td>\n",
       "      <td>0.116706</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068414</td>\n",
       "      <td>0.082220</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066797</td>\n",
       "      <td>0.116706</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242082</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068414</td>\n",
       "      <td>-0.001611</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175175 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        no_of_Redemption_12M_1  no_of_Redemption_12M_10K  \\\n",
       "122101                     0.0                       0.0   \n",
       "46186                      0.0                       0.0   \n",
       "41126                      0.0                       0.0   \n",
       "30070                      0.0                       0.0   \n",
       "232410                     0.0                       0.0   \n",
       "...                        ...                       ...   \n",
       "190609                     0.0                       0.0   \n",
       "216465                     0.0                       0.0   \n",
       "211136                     0.0                       0.0   \n",
       "899                        0.0                       0.0   \n",
       "242082                     0.0                       0.0   \n",
       "\n",
       "        no_of_funds_Redemption_12M_10K  no_of_assetclass_Redemption_12M_10K  \\\n",
       "122101                             0.0                                  0.0   \n",
       "46186                              0.0                                  0.0   \n",
       "41126                              0.0                                  0.0   \n",
       "30070                              0.0                                  0.0   \n",
       "232410                             0.0                                  0.0   \n",
       "...                                ...                                  ...   \n",
       "190609                             0.0                                  0.0   \n",
       "216465                             0.0                                  0.0   \n",
       "211136                             0.0                                  0.0   \n",
       "899                                0.0                                  0.0   \n",
       "242082                             0.0                                  0.0   \n",
       "\n",
       "        redemption_curr  redemption_12M  redemption_rate  \n",
       "122101         0.068414        0.116706         0.004086  \n",
       "46186          0.068414        0.116706         0.004086  \n",
       "41126          0.045743       -0.994636         0.004086  \n",
       "30070          0.067219        0.091516         0.004086  \n",
       "232410         0.068414        0.116706         0.004086  \n",
       "...                 ...             ...              ...  \n",
       "190609         0.068414        0.116706         0.004086  \n",
       "216465         0.068414        0.116706         0.004086  \n",
       "211136         0.068414        0.082220         0.004086  \n",
       "899            0.066797        0.116706         0.004086  \n",
       "242082         0.068414       -0.001611         0.004086  \n",
       "\n",
       "[175175 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    redemption_pipe.fit_transform(X_train),\n",
    "    index=X_train.index,\n",
    "    columns=[col for col in X_train.columns if 'redemption' in col.lower()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_pipe_reg = Pipeline([\n",
    "    ('fillna_values_trans', fillna_values_trans),\n",
    "    ('negative_to_zero_trans', negative_to_zero_trans)\n",
    "])\n",
    "\n",
    "y_train_reg = targ_pipe_reg.fit_transform(y_train_reg)\n",
    "y_test_reg = targ_pipe_reg.transform(y_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the classification target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228198    1\n",
       "240133    1\n",
       "163658    1\n",
       "176954    0\n",
       "69498     1\n",
       "         ..\n",
       "239268    0\n",
       "116033    0\n",
       "238773    1\n",
       "7527      1\n",
       "11875     0\n",
       "Length: 75075, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "targ_pipe_cl = Pipeline([\n",
    "    ('fillna_values_trans', fillna_values_trans),\n",
    "    ('Binarizer', Binarizer(threshold=0))\n",
    "])\n",
    "\n",
    "y_train_cl = pd.Series(\n",
    "    targ_pipe_cl\n",
    "        .fit_transform(y_train_cl.to_frame())\n",
    "        .reshape(-1), index=y_train_cl.index)\n",
    "y_test_cl = pd.Series(\n",
    "    targ_pipe_cl\n",
    "        .transform(y_test_cl.to_frame())\n",
    "        .reshape(-1), index=y_test_cl.index)\n",
    "y_test_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline for the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_pipe = Pipeline([\n",
    "    ('extract_columns_trans', extract_columns_trans),\n",
    "    ('fillna_values_trans', fillna_values_trans),\n",
    "    ('StandardScaler', StandardScaler()),\n",
    "    ('power_transformer', PowerTransformer())\n",
    "])\n",
    "\n",
    "X_train_prepared = feat_pipe.fit(X_train).transform(X_train)\n",
    "X_test_prepared = feat_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORM** Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = pd.DataFrame(\n",
    "    X_train_prepared,\n",
    "    index=X_train.index,\n",
    "    columns=COLS_TO_KEEP\n",
    ")\n",
    "\n",
    "X_test_prepared = pd.DataFrame(\n",
    "    feat_pipe.transform(X_test),\n",
    "    index=X_test.index,\n",
    "    columns=COLS_TO_KEEP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Model building\n",
    "- Evaluate baseline model\n",
    "- Create new models\n",
    "- Create evaluation function and cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Regression\n",
    "\n",
    "Predict the sales of an advisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093150.643517532\n"
     ]
    }
   ],
   "source": [
    "y_baseline = y_test_reg.mean() * np.ones(y_test_reg.shape, dtype='float') # use mean as prediction\n",
    "print(np.sqrt(mean_squared_error(y_test_reg, y_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179451.46304811, 179451.46304811, 179451.46304811, ...,\n",
       "       179451.46304811, 179451.46304811, 179451.46304811])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sklearn` Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=8, n_estimators=10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RandomForestRegressor(n_estimators=10, max_depth=8)\n",
    "rfe.fit(X_train_prepared, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [\n",
    "    'no_of_sales_12M_1', 'no_of_sales_12M_10K', \n",
    "    'no_of_Redemption_12M_10K', 'no_of_funds_sold_12M_1', \n",
    "    'no_of_funds_redeemed_12M_1', 'no_of_fund_sales_12M_10K', \n",
    "    'no_of_funds_Redemption_12M_10K',\n",
    "]\n",
    "X_train_prepared = X_train_prepared.loc[:, subset].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=RandomForestRegressor(max_depth=8, n_estimators=10))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10, max_depth=8)\n",
    "rfe = RFE(rf)\n",
    "rfe.fit(X_train_prepared, y_train_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a boolean mask indicating which columns were selected from the `RFE` fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select columns from RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg_rfe = X_train_prepared.loc[:, rfe.support_]\n",
    "X_test_reg_rfe = X_test_prepared.loc[:, rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestRegressor()\n",
    "rf2.fit(X_train_reg_rfe, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = rf2.predict(X_test_reg_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(y_test_reg, y_test_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to evaulate regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(model, X, y, training=False,):\n",
    "    if training:\n",
    "        print(\"Training Cross Validation Scores:\")\n",
    "        print(-cross_validate(model, X, y, scoring='neg_root_mean_squared_error')['test_score'])\n",
    "        print('-'*55)\n",
    "        preds = model.predict(X)\n",
    "        lim = max(preds.max(), y.max())\n",
    "        fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "        ax.scatter(x=y, y=preds, alpha=0.4)\n",
    "        ax.plot([0, lim], [0, lim])\n",
    "        ax.set_xlim([0, lim])\n",
    "        ax.set_ylim([0, lim])\n",
    "        ax.set_title(\"Actual vs Predicted - Regression\")\n",
    "        ax.set_xlabel(\"Actual\")\n",
    "        ax.set_ylabel(\"Predicted\");\n",
    "    else:\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_reg, y_test_preds))\n",
    "        print(\"Testing Data Performance:\")\n",
    "        print('-'*55)\n",
    "        print(f\"RMSE:\\t{rmse}\")\n",
    "        preds = model.predict(X)\n",
    "        lim = max(preds.max(), y.max())\n",
    "        fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "        ax.scatter(x=y, y=preds, alpha=0.4)\n",
    "        ax.plot([0, lim], [0, lim])\n",
    "        ax.set_xlim([0, lim])\n",
    "        ax.set_ylim([0, lim])\n",
    "        ax.set_title(\"Actual vs Predicted - Regression\")\n",
    "        ax.set_xlabel(\"Actual\")\n",
    "        ax.set_ylabel(\"Predicted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_regression(rf2, X_train_reg_rfe, y_train_reg, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_regression(rf2, X_test_reg_rfe, y_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "### Make function to output deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = pd.Series(rf2.predict(X_test_reg_rfe), index=y_test_reg.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = (\n",
    "    targ_pipe_reg\n",
    "        .named_steps['PowerTransformer']\n",
    "        .inverse_transform(y_test_preds.to_frame())\n",
    "        .squeeze())\n",
    "y_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_deciles(model, X, y, transform=False):\n",
    "    if transform:\n",
    "        results = pd.DataFrame(model.predict(X), index=X.index, columns=['predictions'])\n",
    "        results['actual'] = y.values\n",
    "        results['deciles'] = pd.qcut(results['predictions'], 10,labels=False)\n",
    "        results['predictions'] = (targ_pipe_reg\n",
    "            .named_steps['PowerTransformer']\n",
    "            .inverse_transform(results['predictions'].to_frame())\n",
    "            .squeeze())\n",
    "        results['actual'] = (targ_pipe_reg\n",
    "            .named_steps['PowerTransformer']\n",
    "            .inverse_transform(results['actual'].to_frame())\n",
    "            .squeeze())\n",
    "        results['contact_id'] = results.index.map(adviser_lookup)\n",
    "        return results\n",
    "    else:\n",
    "        results = pd.DataFrame(model.predict(X), index=X.index, columns=['predictions'])\n",
    "        results['actual'] = y.values\n",
    "        results['deciles'] = pd.qcut(results['predictions'], 10, labels=False)\n",
    "        results['contact_id'] = results.index.map(adviser_lookup)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_deciles = output_deciles(rf2, X_test_reg_rfe, y_test_reg, transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_chart = (regression_deciles\n",
    "    .groupby('deciles')\n",
    "    .agg({'actual': ['mean', 'count']})\n",
    "    .droplevel(0, axis=1)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_chart['deciles'] = reg_chart['deciles'].apply(lambda x: (x-10)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,6))\n",
    "reg_chart.plot(kind='bar', x='deciles', y='mean', ax=axes, legend=None)\n",
    "axes.set_xlabel(\"Deciles\", fontsize=14)\n",
    "axes.set_ylabel(\"Average Predicted Sales\", fontsize=14)\n",
    "axes.set_title(\"Average Predicted Sales by Decile\", fontsize=16)\n",
    "axes.spines['top'].set_visible(False);\n",
    "axes.spines['right'].set_visible(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_deciles.sort_values(by='deciles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Classification\n",
    "\n",
    "Predict if an advisor will make at least one sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Baseline-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cl = DummyClassifier(strategy='most_frequent') # use majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cl.fit(X_train_prepared, y_train_cl)\n",
    "y_baseline = dummy_cl.predict(X_test)\n",
    "print(classification_report(y_test_cl, y_baseline, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# find subset of features\n",
    "sfm = SelectFromModel(gbc, threshold='median')\n",
    "sfm.fit(X_train_prepared, y_train_cl)\n",
    "X_train_cl_sfm = pd.DataFrame(\n",
    "    sfm.transform(X_train_prepared),\n",
    "    index=X_train_prepared.index,\n",
    "    columns=X_train_prepared.columns[sfm.get_support()])\n",
    "X_test_cl_sfm = pd.DataFrame(\n",
    "    sfm.transform(X_test_prepared),\n",
    "    index=X_test_prepared.index,\n",
    "    columns=X_test_prepared.columns[sfm.get_support()])\n",
    "\n",
    "# fit model with selected features\n",
    "gbc.fit(X_train_cl_sfm, y_train_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = gbc.predict(X_test_cl_sfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_cl, y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(cl_model, X, y, training=False):\n",
    "    if training:\n",
    "        print(\"Training Cross Validation Scores:\")\n",
    "        print(-cross_validate(cl_model, X, y, scoring='f1')['test_score'])\n",
    "        print('-'*55)\n",
    "        preds = cl_model.predict(X)\n",
    "        print(classification_report(y, preds))\n",
    "    else:\n",
    "        print(\"Testing Data Performance:\")\n",
    "        print('-'*55)\n",
    "        preds = cl_model.predict(X)\n",
    "        print(classification_report(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classifier(gbc, X_train_cl_sfm, y_train_cl, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classifier(gbc, X_test_cl_sfm, y_test_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.predict_proba(X_test_cl_sfm)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_deciles_class(model, X, y):\n",
    "    results = pd.DataFrame(model.predict_proba(X)[:, 1], index=X.index, columns=['predictions'])\n",
    "    results['actual'] = y.values\n",
    "    results['deciles'] = pd.qcut(results['predictions'], 10, labels=False)\n",
    "    results['contact_id'] = results.index.map(adviser_lookup)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_results = output_deciles_class(gbc, X_test_cl_sfm, y_test_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_res1 = (class_results\n",
    "                  .groupby('deciles')\n",
    "                  .agg({'actual': 'sum', 'contact_id': 'count'})\n",
    "                  .rename(columns={'contact_id': 'count'})\n",
    "                  .reset_index()\n",
    "             )\n",
    "class_res1['deciles'] = class_res1['deciles'].apply(lambda x: (x - 10)*-1)\n",
    "class_res1 = class_res1.sort_values(by='deciles')\n",
    "class_res1.to_csv('class_lift.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_preds = pd.Series(gbc.predict(X_train_cl_sfm), index=X_train_cl_sfm.index)\n",
    "cl_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cl_preds = gbc.predict_proba(X_test_cl_sfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_lift_curve(y_test_cl, y_test_cl_preds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Fairness and Bias\n",
    "1. [Visit the Aequitas project website](http://www.datasciencepublicpolicy.org/projects/aequitas/)\n",
    "2. [Aequitas Fairness GitHub](https://github.com/dssg/aequitas)\n",
    "3. [Aequitas API Docs](https://dssg.github.io/aequitas/api/aequitas.html)\n",
    "4. [Aequitas Example](https://dssg.github.io/aequitas/examples/compas_demo.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install aequitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [6.4, 4.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA = 'https://raw.githubusercontent.com/dssg/aequitas/master/examples/data/compas_for_aequitas.csv'\n",
    "df = pd.read_csv(RAW_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data\n",
    "Risk assessment by race\n",
    "\n",
    "COMPAS produces a risk score that predicts a person’s likelihood of commiting a crime in the next two years. The output is a score between 1 and 10 that maps to low, medium or high. For Aequitas, we collapse this to a binary prediction. A score of 0 indicates a prediction of “low” risk according to COMPAS, while a 1 indicates “high” or “medium” risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_palette = sns.diverging_palette(225, 35, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the prediction distributons along the race, sex, and age attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_race = sns.countplot(\n",
    "            x=\"race\", hue=\"score\", \n",
    "            data=df[df.race.isin(['African-American', 'Caucasian', 'Hispanic'])],\n",
    "            palette=aq_palette\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Race by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_by_race = sns.countplot(\n",
    "    x=\"race\", hue=\"label_value\", \n",
    "    data=df[df.race.isin(['African-American', 'Caucasian', 'Hispanic'])], \n",
    "    palette=aq_palette\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions by Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_sex = sns.countplot(x=\"sex\", hue=\"score\", data=df, palette=aq_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels by Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_by_age = sns.countplot(\n",
    "    x=\"sex\", hue=\"label_value\", \n",
    "    data=df, palette=aq_palette\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions by Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_age = sns.countplot(x=\"age_cat\", hue=\"score\", data=df, palette=aq_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels by Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_by_sex = sns.countplot(\n",
    "    x=\"age_cat\", hue=\"label_value\", \n",
    "    data=df, palette=aq_palette\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs above show the base rates for recidivism are higher for black defendants compared to white defendants (.51 vs .39), though the predictions do not match the base rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize a `Group()` instance to see metrics in cross tabulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Group()\n",
    "xtab, _ = g.get_crosstabs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the false negative rates\n",
    "\n",
    "These show how often the model misses someone that does commit another crime within that group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqp = Plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnr = aqp.plot_group_metric(xtab, 'fnr', min_group_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = aqp.plot_group_metric_all(xtab, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
