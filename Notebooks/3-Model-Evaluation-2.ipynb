{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Week 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "- [Capstone Objectives](#Capstone-Objectives)\n",
    "- [Read in Data](#Read-in-Data)\n",
    "    - [Merge 2018 and 2019](#Merge-2018-and-2019)\n",
    "    - [Make advisor dictionary mapper](#Make-advisor-dictionary-mapper)\n",
    "- [Data Cleaning](#Data-Cleaning)\n",
    "    - [Train-Test-Split](#Train-Test-Split)\n",
    "    - [Custom Cleaning Functions](#Custom-Cleaning-Functions)\n",
    "    - [Create Cleaning Pipeline](#Create-Cleaning-Pipeline)\n",
    "- [Model building](#Model-building)\n",
    "- [Make predictions](#Make-predictions)\n",
    "- [Feature Engineering](#Feature-Engineering)\n",
    "    - [Variable Inflation Factor (VIF)](#Variable-Inflation-Factor-(VIF))\n",
    "- [Residuals](#Residuals)\n",
    "- [Classification](#Classification)\n",
    "- [Model Interpretation](#Model-Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Objectives\n",
    "- Assist sales and marketing by improving their targeting\n",
    "- Predict sales for 2019 using the data for 2018\n",
    "- Estimate the probability of adding a new fund in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Transactions.csv\", parse_dates=['refresh_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make advisor dictionary mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adviser_lookup = {\n",
    "    idx: contact_id \n",
    "        for idx, contact_id in enumerate(df['CONTACT_ID'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adviser_lookup[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine `sales_curr` and `sales_12M`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_sales'] = df['sales_curr'] + df['sales_12M']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#EDA)\n",
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -yc conda-forge pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# missing_diagrams = {\n",
    "#     'heatmap': True, 'dendrogram': True, 'matrix':True, 'bar': True,\n",
    "# }\n",
    "\n",
    "# profile = ProfileReport(df, title='Nuveen Profile Report', missing_diagrams=missing_diagrams)\n",
    "\n",
    "# profile.to_file(output_file=\"nuveen_profiling.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you change ANYTHING with the data - besides the above :) - do your train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    'CONTACT_ID', 'no_of_sales_12M_1', 'no_of_Redemption_12M_1',\n",
    "    'no_of_sales_12M_10K', 'no_of_Redemption_12M_10K',\n",
    "    'no_of_funds_sold_12M_1', 'no_of_funds_redeemed_12M_1',\n",
    "    'no_of_fund_sales_12M_10K', 'no_of_funds_Redemption_12M_10K',\n",
    "    'no_of_assetclass_sold_12M_1', 'no_of_assetclass_redeemed_12M_1',\n",
    "    'no_of_assetclass_sales_12M_10K', 'no_of_assetclass_Redemption_12M_10K',\n",
    "    'No_of_fund_curr', 'No_of_asset_curr', 'AUM', 'sales_curr', 'sales_12M',\n",
    "    'redemption_curr', 'redemption_12M', 'new_Fund_added_12M',\n",
    "    'redemption_rate', 'aum_AC_EQUITY', 'aum_AC_FIXED_INCOME_MUNI',\n",
    "    'aum_AC_FIXED_INCOME_TAXABLE', 'aum_AC_MONEY', 'aum_AC_MULTIPLE',\n",
    "    'aum_AC_PHYSICAL_COMMODITY', 'aum_AC_REAL_ESTATE', 'aum_AC_TARGET',\n",
    "    'aum_P_529', 'aum_P_ALT', 'aum_P_CEF', 'aum_P_ETF', 'aum_P_MF',\n",
    "    'aum_P_SMA', 'aum_P_UCITS', 'aum_P_UIT', 'refresh_date',\n",
    "]\n",
    "TARGETS = 'total_sales'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rows = df['refresh_date'].dt.year.isin([2017, 2018, 2019])\n",
    "testing_rows = df['refresh_date'].dt.year.isin([2020])\n",
    "\n",
    "X = df.loc[training_rows, FEATURES].copy()\n",
    "y_reg = df.loc[training_rows, TARGETS].copy()\n",
    "y_cl = df.loc[training_rows, 'new_Fund_added_12M'].copy()\n",
    "\n",
    "y_holdout_test = df.loc[testing_rows, TARGETS].copy() # forget about this for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Cleaning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create functions that do some basic housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_columns(df):\n",
    "    '''extract out columns not listed in COLS_TO_DROP variable'''\n",
    "    cols_to_keep = [col for col in df.columns if col not in COLS_TO_DROP]\n",
    "    return df.loc[:, cols_to_keep].copy()\n",
    "\n",
    "\n",
    "def fillna_values(df):\n",
    "    '''fill nan values with zero'''\n",
    "    if isinstance(df, type(pd.Series(dtype='float64'))):\n",
    "        return df.fillna(0)\n",
    "    num_df = df.select_dtypes(include=['number']).fillna(0)\n",
    "    non_num_df = df.select_dtypes(exclude=['number'])\n",
    "    return pd.concat([num_df, non_num_df], axis=1)\n",
    "\n",
    "\n",
    "def negative_to_zero(series):\n",
    "    if isinstance(series, type(pd.Series(dtype='float64'))):\n",
    "        return series.apply(lambda x: max(0, x))\n",
    "    else:\n",
    "        return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Create Cleaning Pipeline\n",
    "\n",
    "- Pipeline for target variable\n",
    "- Pipeline for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_columns_trans = FunctionTransformer(extract_columns)\n",
    "fillna_values_trans = FunctionTransformer(fillna_values)\n",
    "negative_to_zero_trans = FunctionTransformer(negative_to_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pipeline for regression target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_redemption(df):\n",
    "    redemp_cols = [col for col in df.columns if 'redemption' in col.lower()]\n",
    "    return df[redemp_cols].copy()\n",
    "\n",
    "def replace_with_zero(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: min(0, x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_redemption_trans = FunctionTransformer(extract_redemption)\n",
    "replace_with_zero_trans = FunctionTransformer(replace_with_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redemption_pipe = Pipeline([\n",
    "    ('extract_redemption_trans', extract_redemption_trans),\n",
    "    ('replace_with_zero_trans', replace_with_zero_trans),\n",
    "    ('StandardScaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    redemption_pipe.fit_transform(X_train),\n",
    "    index=X_train.index,\n",
    "    columns=[col for col in X_train.columns if 'redemption' in col.lower()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_pipe_reg = Pipeline([\n",
    "    ('fillna_values_trans', fillna_values_trans),\n",
    "    ('negative_to_zero_trans', negative_to_zero_trans)\n",
    "])\n",
    "\n",
    "y_train_reg = targ_pipe_reg.fit_transform(y_train_reg)\n",
    "y_test_reg = targ_pipe_reg.transform(y_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the classification target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "targ_pipe_cl = Pipeline([\n",
    "    ('fillna_values_trans', fillna_values_trans),\n",
    "    ('Binarizer', Binarizer(threshold=0))\n",
    "])\n",
    "\n",
    "y_train_cl = pd.Series(\n",
    "    targ_pipe_cl\n",
    "        .fit_transform(y_train_cl.to_frame())\n",
    "        .reshape(-1), index=y_train_cl.index)\n",
    "y_test_cl = pd.Series(\n",
    "    targ_pipe_cl\n",
    "        .transform(y_test_cl.to_frame())\n",
    "        .reshape(-1), index=y_test_cl.index)\n",
    "y_test_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline for the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_pipe = Pipeline([\n",
    "    ('extract_columns_trans', extract_columns_trans),\n",
    "    ('fillna_values_trans', fillna_values_trans),\n",
    "    ('StandardScaler', StandardScaler()),\n",
    "    ('power_transformer', PowerTransformer())\n",
    "])\n",
    "\n",
    "X_train_prepared = feat_pipe.fit(X_train).transform(X_train)\n",
    "X_test_prepared = feat_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORM** Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = pd.DataFrame(\n",
    "    X_train_prepared,\n",
    "    index=X_train.index,\n",
    "    columns=COLS_TO_KEEP\n",
    ")\n",
    "\n",
    "X_test_prepared = pd.DataFrame(\n",
    "    feat_pipe.transform(X_test),\n",
    "    index=X_test.index,\n",
    "    columns=COLS_TO_KEEP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prepared.hist(bins=30, figsize=(18,18));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Model building\n",
    "- Evaluate baseline model\n",
    "- Create new models\n",
    "- Create evaluation function and cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_prepared, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-cross_validate(\n",
    "    lr, \n",
    "    X_train_prepared, \n",
    "    y_train_reg, \n",
    "    cv=3, \n",
    "    scoring='neg_root_mean_squared_error', \n",
    "    return_train_score=True\n",
    ")['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot of predictions vs actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reg_preds = lr.predict(X_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "axes.scatter(x=y_test_reg, y=y_test_reg_preds)\n",
    "\n",
    "axes.plot([0, 20000000], [0,20000000])\n",
    "axes.set_title(\"Actual vs Predicted - Regression\")\n",
    "axes.set_xlabel(\"Actual\")\n",
    "axes.set_ylabel(\"Predicted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    print(\"Cross Validation Scores:\")\n",
    "    print(-cross_validate(model, X, y, scoring='neg_root_mean_squared_error')['test_score'])\n",
    "    print('-'*55)\n",
    "    preds = model.predict(X)\n",
    "    lim = max(preds.max(), y.max())\n",
    "    fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "    ax.scatter(x=y, y=preds, alpha=0.4)\n",
    "    ax.plot([0, lim], [0, lim])\n",
    "    ax.set_xlim([0, lim])\n",
    "    ax.set_ylim([0, lim])\n",
    "    ax.set_title(\"Actual vs Predicted - Regression\")\n",
    "    ax.set_xlabel(\"Actual\")\n",
    "    ax.set_ylabel(\"Predicted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(lr, X_test_prepared, y_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reg_preds = lr.predict(X_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the residuals\n",
    "residuals = y_test_reg_preds - y_test_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions vs residuals\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14,10))\n",
    "\n",
    "# plot scatter plot on upper left plot\n",
    "axes[0,0].scatter(x=y_test_reg_preds, y=residuals, alpha=0.5)\n",
    "axes[0,0].set(xlabel='Predictions', ylabel='Residuals')\n",
    "\n",
    "# plot a hist on upper right plot\n",
    "axes[0,1].hist(residuals, bins=50)\n",
    "axes[0,1].set(xlabel='Residuals', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import qqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(residuals, fit=True, line='r', ax=axes[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(X, y, model):\n",
    "    # print classification report\n",
    "    # create lift charts\n",
    "    # create gains charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_prepared, y_train_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cl_preds = rf.predict_proba(X_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_lift_curve(y_test_cl, y_test_cl_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(y_test_cl_preds)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
